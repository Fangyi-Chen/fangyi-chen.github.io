<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <meta name="author" content="jasonlai">
  <title>SemiFlow</title>

  <!-- CSS  -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/font-awesome.min.css" rel="stylesheet">

  <!--<meta property="og:image" content="http://gph.is/2oZQz8h" />-->
</head>
<body>
  
  <div class="navbar-fixed">

    <nav class="grey darken-4" role="navigation">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
        <ul class="left hide-on-med-and-down">
          <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#abstract">Abstract</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#paper">Paper</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#reference">References</a></li>
        </ul>

        <a href="#" data-activates="nav-mobile" class="button-collapse"><i class="material-icons">menu</i></a>
      </div>
    </nav>
  </div>
  




  <div class="section no-pad-bot" id="index-banner">
    <div class="container scrollspy" id="home">

      <h4 class="header center black-text">Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks</h4>

      <br>

      <div class="row center">
        <h5 class="header col m4 s12">
          <div class="author"><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></div>
          <div class="school"><a href="http://www.ucmerced.edu/" target="blank">University of California, Merced</a></div>
        </h5>

        <h5 class="header col m4 s12">
          <div class="author"><a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a></div>
          <div class="school"><a href="http://www.vt.edu/" target="blank">Virginia Tech</a></div>
        </h5>

        <h5 class="header col m4 s12">
          <div class="author"><a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a></div>
          <div class="school"><a href="http://www.ucmerced.edu/" target="blank">University of California, Merced</a></div>
        </h5>
        
      </div>

    </div>
  </div>


  <div class="container">

    <div class="section">

      <!--   Icon Section   -->
      <div class="row center">
        <div class="col l6 m12 s12">
          <img class="responsive-img" src="images/baseline.jpg">
          <div class="note">
            Baseline semi-supervised method
          </div>
        </div>

        <div class="col l6 m12 s12">
          <img class="responsive-img" src="images/proposed.jpg">
          <div class="note">
            Proposed semi-supervised method
          </div>
        </div>
        
      </div>

    </div>

    <br>

    <div class="row section scrollspy" id="abstract">
      <div class="title">Abstract</div>
Convolutional neural networks (CNNs) have recently been applied to the optical flow estimation problem.
As training the CNNs requires sufficiently large amounts of labeled data, existing approaches resort to synthetic, unrealistic datasets.
On the other hand, unsupervised methods are capable of leveraging real-world videos for training where the ground truth flow fields are not available.
These methods, however, rely on the fundamental assumptions of brightness constancy and spatial smoothness priors that do not hold near motion boundaries.
In this paper, we propose to exploit unlabeled videos for semi-supervised learning of optical flow with a Generative Adversarial Network.
Our key insight is that the adversarial loss can capture the structural patterns of flow warp errors without making explicit assumptions.
Extensive experiments on benchmark datasets demonstrate that the proposed semi-supervised algorithm performs favorably against purely supervised and baseline semi-supervised learning schemes.
    </div>

    
    <div class="row section scrollspy" id="paper">
      <div class="title">Papers</div>
      <br>

      <div class="row">
        <div class="col s12">
          <div id='paper-thumbnail'>
            <a href="http://papers.nips.cc/paper/6639-semi-supervised-learning-for-optical-flow-with-generative-adversarial-networks.pdf" target="_blank">
              <img class="responsive-img" src="images/thumbnail.jpg">
            </a>
            <div class="center-align subtitle"><a href="http://papers.nips.cc/paper/6639-semi-supervised-learning-for-optical-flow-with-generative-adversarial-networks.pdf" target="_blank">NIPS17</a></div>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col s12">
          <div id='paper-thumbnail'>
            <a href="nips17_semiFlowGAN_supp.pdf" target="_blank">
              <img class="responsive-img" src="images/thumbnail_supp.jpg">
            </a>
            <div class="center-align subtitle"><a href="nips17_semiFlowGAN_supp.pdf" target="_blank">Supplementary Material</a></div>
          </div>
        </div>
      </div>

    </div>


    <div class="row">
      <div class="subtitle">Citation</div>
      <p>Wei-Sheng Lai, Jia-Bin Huang, and Ming-Hsuan Yang, "Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks", in Neural Information Processing Systems, 2017.</p>

      <br>

      <div class="subtitle">Bibtex</div>
      <pre>
@inproceedings{Lai-NIPS-2017,
    author    = {Lai, Wei-Sheng and Huang, Jia-Bin and Yang, Ming-Hsuan}, 
    title     = {Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks}, 
    booktitle = {Neural Information Processing Systems},
    year      = {2017}
}
</pre>
    </div>


    <div class="row section scrollspy" id="reference">
      <div class="title">References</div>
      <ul>
        <li>&bull; 
          <a href="https://arxiv.org/abs/1504.06852" target="blank">FlowNet: Learning Optical Flow with Convolutional Networks</a>, ICCV, 2015.
        </li>
        <li>&bull; 
          <a href="https://arxiv.org/abs/1612.01925" target="blank">FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks</a>, CVPR, 2017.
        </li>
        <li>&bull; 
          <a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr" target="blank">Optical Flow Estimation using a Spatial Pyramid Network</a>, CVPR, 2017.
        </li>
      </ul>
    </div>

  </div>

  <footer class="page-footer grey lighten-3">
    
      <div class="row">
        <div class="col l4 offset-l4 s12">
          <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=330&t=tt&d=fhGpuMgoLYXytRWhcIV-396rCSmJYtpAJdk3tTNbAnY"></script>
        </div>
      </div>
    
    <div class="footer-copyright center black-text">
      Copyright Â© Jason Lai 2017
    </div>
  </footer>


  <!--  Scripts-->
  <script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="js/materialize.js"></script>
  <script src="js/init.js"></script>

  </body>
</html>
