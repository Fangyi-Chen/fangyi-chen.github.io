<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <meta name="author" content="jasonlai">
  <title>Fangyi Chen's Homepage</title>

  <!-- CSS  -->
  <link href="css/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/aos.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/font-awesome.min.css" rel="stylesheet" >
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>

  <link rel="shortcut icon" href="images/deer.png">
</head>
<body>
  
  <div class="navbar-fixed">

    <nav class="">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#about">About</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#publication">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#patents">Patents</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#activities">Activity</a></li>
        </ul>
      </div>
    </nav>
  </div>

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">
  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="images/profile.png">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Fangyi Chen</h5>

        <hr>

        <h6 class="profile-link">Ph.D. Candidate</h6 class="profile-link">
        <h6 class="profile-link">Dept. of Electrical and Computer Engineering</h6 class="profile-link">
        <h6 class="profile-link">Carnegie Mellon University</h6 class="profile-link">

        <h1></h1>

        <a href="Fangyi_Chen_selected.pdf" target="blank"><img class="responsive-img social-photo " src="images/icons/cv.png"></a>

        <a href="https://scholar.google.com/citations?user=Wq3W7QcAAAAJ&hl=en" target="blank"><img class="responsive-img social-photo " src="images/icons/google_scholar.png"></a>

        <a href="https://github.com/Fangyi-Chen" target="blank"><img class="responsive-img social-photo " src="images/icons/github.png"></a>

        <a href="https://www.linkedin.com/in/fangyi-chen-9b645719b/" target="blank"><img class="responsive-img social-photo" src="images/icons/linkedin.png"></a>

    </div>
    
  </div>

  <div class="parallax"><img src="images/cover_blur.png" alt="Unsplashed background img 1"></div>
  
</div>


<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="about">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">About Me</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        I am a Ph.D. candidate in the Department of Electrical and Computer Engineering at
        <a href="https://www.cmu.edu/" target="blank">Carnegie Mellon University</a></h6 class="profile-link"> since spring 2020.
        At CMU, I am affiliated with the CyLab Security & Privacy Institute and advised by
        Prof. <a href="https://www.ece.cmu.edu/directory/bios/savvides-marios.html" target="blank">Marios Savvides</a>.
        I obtained my M.S. degree from the Department of Electrical and Computer Engineering at
        <a href="https://www.pitt.edu/" target="blank">PITT</a></h6 class="profile-link"> in 2018, under the advicement of
        Prof. <a href="https://www.engineering.pitt.edu/people/faculty/zhi-hong-mao/" target="blank">Zhi-Hong Mao</a>.
        I got my B.E. degree in Electrical Engineering and Automation at
        <a href="https://laps.ncepu.edu.cn/" target="blank">NCEPU</a></h6 class="profile-link"> in 2017.
      </p>
      <p>
        My research interest lies in deep learning and computer vision, with a focus on <b>multimodal large language model</b>
        and <b>open-world scene understanding</b>.
        I am lucky to have opportunities to work with
        <a href="https://scholar.google.com/citations?user=g2ZUg7AAAAAJ&hl=en" target="blank">Ker-Jiun Wang</a>,
        <a href="https://www.linkedin.com/in/yutongzh/" target="blank">Yutong Zheng</a>,
        <a href="https://dkpal.github.io/" target="blank">Dipan Pal</a>,
        <a href="https://www.linkedin.com/in/raied-aljadaany-3922b01a9/?originalSubdomain=sa" target="blank">Raied Aljadaany</a>,
        and
        <a href="https://sites.google.com/andrew.cmu.edu/zcckernel" target="blank">Chenchen Zhu</a>.
      </p>


    </div>

    <div class="row">

      <ul class="timeline">
          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
            <div class="timeline-badge">
              <i class="fa fa-plus-circle invert" id=""></i>
            </div>
            <div class="timeline-panel">
              <div class="col s4">
                <a href="https://www.cmu.edu/" target="blank">
                  <img class="responsive-img about-photo" src="images/about/cmu2.jpg">
                </a>
              </div>
              <div class="col s8">
                <div class="timeline-heading">
                  <a href="https://www.cmu.edu/" target="blank">
                    Carnegie Mellon University
                  </a>
                </div>
                <div class="timeline-body">
                  <p>Ph.D. Student</p>
                  <p>Jan. 2020 - Present</p>
                </div>
              </div>
            </div>
          </li>

          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
            <div class="timeline-badge">
              <i class="fa fa-plus-circle invert" id=""></i>
            </div>
            <div class="timeline-panel">
              <div class="col s4">
                <a href="https://www.bytedance.com/en/" target="blank">
                  <img class="responsive-img about-photo" src="images/about/bytedance.jpeg">
                </a>
              </div>
              <div class="col s8">
                <div class="timeline-heading">
                  <a href="https://www.bytedance.com/en/" target="blank">
                    ByteDance
                  </a>
                </div>
                <div class="timeline-body">
                  <p>Research Intern (Intelligent Creation-Vision and Graphics)</p>
                  <p>May. 2024 - Aug. 2024</p>
                </div>
              </div>
            </div>
          </li>

          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4 timeline-logo-inverted">
                  <a href="https://www.cylab.cmu.edu/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/cylab.jpeg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.cylab.cmu.edu/" target="blank">
                      CMU CyLab
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research Associate, Jan. 2019 - Nov. 2019</p>
                  </div>
                </div>
                
              </div>
          </li>

          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.pitt.edu/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/pitt.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.pitt.edu/" target="blank">
                      University of Pittsburgh
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>M.S.</p>
                    <p>Aug. 2017 - Dec. 2018</p>
                  </div>
                </div>
              </div>
          </li>

          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4 timeline-logo-inverted">
                  <a href="https://laps.ncepu.edu.cn/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/ncepu.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://laps.ncepu.edu.cn/" target="blank">
                      North China Electric Power University
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>B.E.</p>
                    <p>Sept. 2013 - May. 2017</p>
                  </div>
                </div>

              </div>
          </li>
          <!--
          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.microsoft.com/en-us/research/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/MSR.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.microsoft.com/en-us/research/" target="blank">
                      Microsoft Research
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research intern</p>
                    <p>May 2016 - Aug. 2016</p>
                  </div>
                </div>
              </div>
          </li>

          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="http://www.ucmerced.edu/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/ucmerced.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="http://www.ucmerced.edu/" target="blank">
                      University of California, Merced
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Ph.D.</p>
                    <p>Aug. 2015 - Jul. 2019</p>
                  </div>
                </div>

              </div>

          </li>

          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.sinica.edu.tw/en" target="blank">
                    <img class="responsive-img about-photo" src="images/about/sinica.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.sinica.edu.tw/en" target="blank">
                      Academia Sinica
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research assistant</p>
                    <p>Aug. 2014 - Jul. 2015</p>
                  </div>
                </div>
              </div>
          </li>

          <li  class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="http://www.ntu.edu.tw/english/index.html" target="blank">
                    <img class="responsive-img about-photo" src="images/about/NCEPU.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="http://www.ntu.edu.tw/english/index.html" target="blank">
                      National Taiwan University
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>B.S., M.S.</p>
                    <p>Sep. 2008 - Jul. 2015</p>
                  </div>
                </div>

              </div>
          </li>
          -->
          <li class="clearfix no-float"></li>
      </ul>

    </div>
  </div>
</div>


<!--==========================================
                   Publication
===========================================-->
<div class="section publication-section scrollspy" id="publication">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

    <!-- RTGen -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://unavailablenowwww.com" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/RTGen.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">RTGen: Generating Region-Text Pairs for Open-Vocabulary Object Detection</div>
          <div class="paper-author">
            <b>Fangyi Chen*</b>,
            Han Zhang*,
            Zhantao Yang,
            Hao Chen,
            Kai Hu
            and
            Marios Savvides
          </div>
          <div class="paper-conf">Preprint</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/pdf/2405.19854" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/seermer/RTGen" target="blank">code</a>
          </div>
        </div>
      </div>

    <!-- SQR -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/pdf/2212.07593.pdf" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/sqr.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Enhanced Training of Query-Based Object Detection via Selective Query Recollection</div>
          <div class="paper-author">
            <b>Fangyi Chen</b>,
            Han Zhang,
            Kai Hu,
            Yukai Huang,
            Chenchen Zhu
            and
            Marios Savvides
            </div>
          <div class="paper-conf">Proceedings of the IEEE conference on computer vision and pattern recognition (<b>CVPR</b>), 2023</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/pdf/2212.07593.pdf" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/Fangyi-Chen/SQR" target="blank">code</a>
          </div>
        </div>
      </div>

      <!-- unitail -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/pdf/2204.00298.pdf" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/unitail.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Unitail: Detecting, Reading, and Matching in Retail Scene</div>
          <div class="paper-author">
            <b>Fangyi Chen</b>,
            Han Zhang,
            Zaiwang Li,
            Jiachen Dou,
            Shentong Mo,
            Hao Chen,
            Yongxin Zhang,
            Uzair Ahmed,
            Chenchen Zhu
            and
            Marios Savvides
          </div>
          <div class="paper-conf">European conference on computer vision (<b>ECCV</b>), 2022</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/pdf/2204.00298.pdf" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://unitedretail.github.io/" target="blank">project website</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/Fangyi-Chen/mmocr-unitail" target="blank">code</a>
          </div>
        </div>
      </div>

      <!-- srrfsd -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.pdf" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/srrfsd.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection</div>
          <div class="paper-author">
            Chenchen Zhu,
            <b>Fangyi Chen</b>,
            Uzair Ahmed,
            Zhiqiang Shen
            and
            Marios Savvides
          </div>
          <div class="paper-conf">Proceedings of the IEEE conference on computer vision and pattern recognition (<b>CVPR</b>), 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.pdf" target="blank">paper</a>
          </div>
        </div>
      </div>

      <!-- sapd -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/pdf/1911.12448.pdf" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/sapd.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Soft Anchor-Point Object Detection</div>
          <div class="paper-author">
            Chenchen Zhu,
            <b>Fangyi Chen</b>,
            Zhiqiang Shen
            and
            Marios Savvides
          </div>
          <div class="paper-conf">European conference on computer vision (<b>ECCV</b>), 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/pdf/1911.12448.pdf" target="blank">paper</a>
          </div>
        </div>
      </div>

      <!-- NCMS -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.sciencedirect.com/science/article/pii/S1077314220300953" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/ncms.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">NCMS: Towards accurate anchor free object detection through ùìÅ2 norm calibration and multi-feature selection</div>
          <div class="paper-author">
            <b>Fangyi Chen</b>,
            Chenchen Zhu,
            Zhiqiang Shen,
            Han Zhang
            and
            Marios Savvides
          </div>
          <div class="paper-conf">Computer Vision and Image Understanding (<b>CVIU</b>), Volumn 200, 103050</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://www.sciencedirect.com/science/article/pii/S1077314220300953" target="blank">paper</a>
          </div>
        </div>
      </div>

      <!-- icassp -->
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/pdf/2002.05274.pdf" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/brl.jpg">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Solving missing-annotation object detection with background recalibration loss</div>
          <div class="paper-author">
            Han Zhang,
            <b>Fangyi Chen</b>,
            Zhiqiang Shen,
            Qiqi Hao,
            Chenchen Zhu
            and
            Marios Savvides
          </div>
          <div class="paper-conf">IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/pdf/2002.05274.pdf" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/Dwrety/mmdetection-selective-iou" target="blank">code</a>
          </div>
        </div>
      </div>

      <!-- patents on smart store
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/ai4retail.png">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">AI system and method for Retail</div>

          <div>
            <img class="responsive-img icon" src="images/icons/patent.png">
            <a href="https://patentimages.storage.googleapis.com/6c/4f/d2/c028419482ce23/US20220058425A1.pdf" target="blank">US Patent App. 17/408,778</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/patent.png">
            <a href="https://patentimages.storage.googleapis.com/d0/1f/08/fe7e8967cd5f3b/US20220083959A1.pdf" target="blank">US Patent App. 17/425,293</a>
          </div>
        </div>
      </div>
      -->

      <!--
      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/fusion_deblur/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/siggraph22_fusion_deblur.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Face Deblurring using Dual Camera Fusion on Mobile Phones</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <a href="https://www.linkedin.com/in/lcchu/" target="blank">Lun-Cheng Chu</a>, 
            <a href="https://www.linkedin.com/in/xiaotong-wu-127705a0/" target="blank">Xiaotong Wu</a>, 
            <a href="https://www.linkedin.com/in/sung-fang-tsai-5455b43b/" target="blank">Sung-Fang Tsai</a>, 
            <a href="https://scholar.google.com/citations?hl=en&user=h_Izm-wAAAAJ&view_op=list_works&sortby=pubdate" target="blank">Michael Krainin</a>, 
            <a href="https://deqings.github.io/" target="blank">Deqing Sun</a>, 
            and
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            </div>
          <div class="paper-conf">ACM Transactions on Graphics (SIGGRAPH), 2022</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2207.11617" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/fusion_deblur/" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2105.13016" target="blank">
            <img class="responsive-img" src="images/publications/wacv22_3dstyletransfer.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Stylizing 3D Scene via Implicit Representation and HyperNetwork</div>
          <div class="paper-author"> 
            Pei-Ze Chiang, 
            Meng-Shiun Tsai, 
            <a href="https://hytseng0509.github.io/" target="blank">Hung-Yu Tseng</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            and
            <a href="https://walonchiu.github.io/" target="blank">Wei-Chen Chiu</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2105.13016" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://ztex08010518.github.io/3dstyletransfer/" target="blank">project website</a>
          </div>
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2102.01279" target="blank">
            <img class="responsive-img" src="images/publications/dvs.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Deep Online Fused Video Stabilization</div>
          <div class="paper-author"> 
            <a href="http://pages.cs.wisc.edu/~zhmeishi/" target="blank">Zhenmei Shi</a>, 
            <a href="http://fuhaoshi.com/" target="blank">Fuhao Shi</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            and
            <a href="http://pages.cs.wisc.edu/~yliang/" target="blank">Yingyu Liang</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2102.01279" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://zhmeishi.github.io/dvs/" target="blank">project website</a>
          </div>
        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/video_face_correction/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/tip_video_face_correction.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Correcting Face Distortion in Wide-Angle Videos</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>,
            and
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
            </div>
          <div class="paper-conf">IEEE Transactions on Image Processing <b>(TIP)</b>, 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2111.09950" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/video_face_correction/" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/SOLD/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr20_reflection.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Learning to See Through Obstructions with Layered Decomposition</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>
          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2020</div>
          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b> 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            paper
            <a href="https://arxiv.org/abs/2004.01180" target="blank">[CVPR'20]</a>
            <a href="https://arxiv.org/abs/2008.04902" target="blank">[TPAMI'21]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            project website
            <a href="https://alex04072000.github.io/ObstructionRemoval/" target="blank">[CVPR'20]</a>
            <a href="https://alex04072000.github.io/SOLD/" target="blank">[TPAMI'21]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            code
            <a href="https://github.com/alex04072000/ObstructionRemoval" target="blank">[CVPR'20]</a>
            <a href="https://github.com/alex04072000/SOLD" target="blank">[TPAMI'21]</a>
          </div>
        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted.pdf" target="blank">
            <img class="responsive-img paper-img" src="images/publications/pami21_adaptive.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Toward Real-World Super-Resolution via Adaptive Downsampling Models</div>
          <div class="paper-author">
            <a href="https://scholar.google.co.kr/citations?user=nWaSdu0AAAAJ&hl=en" target="blank">Sanghyun Son*</a>, 
            Jaeha Kim*,
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>,
            and
            <a href="https://cv.snu.ac.kr/index.php/~kmlee/" target="blank">Kyoung Mu Lee</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b> 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted_supp.pdf" target="blank">supplementary material</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/FuSta/" target="blank">
            <img class="responsive-img" src="images/publications/iccv21_nervis.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Hybrid Neural Fusion for Full-frame Video Stabilization</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu*</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>,
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>

          <div class="paper-conf">IEEE International Conference on Computer Vision <b>(ICCV)</b>, 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2102.06205" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://alex04072000.github.io/FuSta/" target="blank">project website</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/alex04072000/FuSta" target="blank">code</a>
          </div>
        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2012.05903" target="blank">
            <img class="responsive-img" src="images/publications/arxiv_portraitNerf.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Portrait Neural Radiance Fields from a Single Image</div>
          <div class="paper-author"> 
            <a href="http://chengao.vision/" target="blank">Chen Gao</a>, 
            <a href="https://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>
          <div class="paper-conf">arXiv, 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2012.05903" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://portrait-nerf.github.io/" target="blank">project website</a>
          </div>
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv.pdf" target="blank">
            <img class="responsive-img" src="images/publications/wacv21_dual.jpg">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution</div>
          <div class="paper-author"> 
            Min-Yuan Tseng, 
            <a href="https://yenchungchen.github.io/" target="blank">Yen-Chung Chen</a>, 
            Yi-Lun Lee, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://sites.google.com/site/yihsuantsai/" target="blank">Yi-Hsuan Tsai</a>
            and
            <a href="https://walonchiu.github.io/" target="blank">Wei-Chen Chiu</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv.pdf" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv_supp.pdf" target="blank">Supplementary material</a>
          </div> 
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2010.10056" target="blank">
            <img class="responsive-img" src="images/publications/wacv21_vst.png">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Real-time Localized Photorealistic Video Style Transfer</div>
          <div class="paper-author"> 
            <a href="https://xidexia.github.io/" target="blank">Xide Xia</a>, 
            <a href="https://people.csail.mit.edu/tfxue/" target="blank">Tianfan Xue</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Zheng Sun, 
            Abby Chang, 
            <a href="http://people.bu.edu/bkulis/" target="blank">Brian Kulis</a>
            and
            <a href="https://people.csail.mit.edu/jiawen/" target="blank">Jiawen Chen</a>
          </div>

          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2010.10056" target="blank">paper</a>
          </div>
          
        </div>
      </div>



      
      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/SingleHDR/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr20_hdr.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Single-Image HDR Reconstruction by Learning to Reverse the Camera Pipeline</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu*</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai*</a></b>, 
            <a href="https://www.cmlab.csie.ntu.edu.tw/~nothinglo/" target="blank">Yu-Sheng Chen</a>, 
            Yi-Lung Kao, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2004.01179" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://alex04072000.github.io/SingleHDR/" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/alex04072000/SingleHDR" target="blank">code</a>
          </div>
          
        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://ieeexplore.ieee.org/document/" target="blank">
            <img class="responsive-img" src="images/publications/tip20_depth_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Dynamic Scene Deblurring by Depth Guided Model</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/lerenhanli/homepage" target="blank">Lerenhan Li</a>, 
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Changxin Gao,
            Nong Sang
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Image Processing <b>(TIP)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://ieeexplore.ieee.org/document/" target="blank">paper</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://aliensunmin.github.io/project/360-VQA/" target="blank">
            <img class="responsive-img" src="images/publications/wacv20_360vqa.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Visual Question Answering on 360&deg; Images</div>
          <div class="paper-author"> 
            <a href="https://shihhanchou.github.io/" target="blank">Shih-Han Chou</a>, 
            <a href="http://www-scf.usc.edu/~weilunc/" target="blank">Wei-Lun Chao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://aliensunmin.github.io/" target="blank">Min Sun</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">Winter Conference on Applications of Computer Vision <b>(WACV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2001.03339" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://aliensunmin.github.io/project/360-VQA/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      
      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/site/ziyishenmi/cvpr18_face_deblur" target="blank">
            <img class="responsive-img" src="images/publications/cvpr18_face_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Deep Semantic Face Deblurring</div>
          <div class="paper-author">
            <a href="https://sites.google.com/site/ziyishenmi/" target="blank">Ziyi Shen</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Tingfa Xu, 
            <a href="http://jankautz.com/" target="blank">Jan Kautz</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2018</div>
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1803.03345" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2001.06822" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/site/ziyishenmi/cvpr18_face_deblur" target="blank">project website</a>
          </div>
          
        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1807.10806" target="blank">
            <img class="responsive-img" src="images/publications/bmvc18_SR_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Gated Fusion Network for Degraded Image Super Resolution</div>
          <div class="paper-author"> 
            <a href="http://xinyizhang.tech/" target="blank">Xinyi Zhang</a>, 
            Hang Dong, 
            <a href="https://eng.ucmerced.edu/people/zhu" target="blank">Zhe Hu</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Fei Wang, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">British Machine Vision Conference  <b>(BMVC)</b>, 2018 (<font color="red">Oral presentation</font>)</div> 
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1807.10806" target="blank">conference version</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://link.springer.com/article/10.1007/s11263-019-01285-y" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://xinyizhang.tech/bmvc2018/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/video_stitching/" target="blank">
            <img class="responsive-img" src="images/publications/bmvc19_video_stitching.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Video Stitching for Linear Camera Arrays</div>
          <div class="paper-author"> 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://alumni.soe.ucsc.edu/~orazio/" target="blank">Orazio Gallo</a>, 
            <a href="http://www.gujinwei.org/" target="blank">Jinwei Gu</a>, 
            <a href="https://scholar.google.com/citations?hl=en&user=t4rgICIAAAAJ&view_op=list_works&sortby=pubdate" target="blank">Deqing Sun</a>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
            and
            <a href="http://jankautz.com/" target="blank">Jan Kautz</a>
          </div>

          <div class="paper-conf">British Machine Vision Conference <b>(BMVC)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1907.13622" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/video_stitching/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/sig19.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Distortion-Free Wide-Angle Portraits on Camera Phones</div>
          <div class="paper-author">
            <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            and
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            </div>
          <div class="paper-conf">ACM Transactions on Graphics <b>(SIGGRAPH)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/shih_sig19_lowres.pdf" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/view/wenbobao/dain" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr19_DAIN.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Depth-Aware Video Frame Interpolation</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/wenbobao/home" target="blank">Wenbo Bao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://sites.google.com/site/chaoma99/" target="blank">Chao Ma</a>, 
            Xiaoyun Zhang, 
            Zhiyong Gao, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1904.00830" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/wenbobao/dain" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/baowenbo/DAIN" target="blank">code</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/view/wenbobao/memc-net" target="blank">
            <img class="responsive-img paper-img" src="images/publications/MEMCNet.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Frame Interpolation and Enhancement</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/wenbobao/home" target="blank">Wenbo Bao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Xiaoyun Zhang, 
            Zhiyong Gao, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1810.08768" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/wenbobao/memc-net" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/lapsrn" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr17_LapSRN.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              <a href="https://sites.google.com/site/jbhuang0604/" target="blank">Jia-Bin Huang</a>, 
              <a href="http://vision.ai.illinois.edu/ahuja.html" target="blank">Narendra Ahuja</a>, and 
              <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2017</div>
          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b>, 2018</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://www.wslai.net/publications/lapsrn/papers/cvpr17_LapSRN.pdf" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1710.01992" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/lapsrn" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/phoenix104104/LapSRN" target="blank">code</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/video_consistency/" target="blank">
            <img class="responsive-img" src="images/publications/eccv18_video_consistency.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Learning Blind Video Temporal Consistency</div>
          <div class="paper-author"> 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://filebox.ece.vt.edu/~jbhuang/index.html" target="blank">Jia-Bin Huang</a>, 
            <a href="http://www.oliverwang.info/" target="blank">Oliver Wang</a>, 
            <a href="https://research.adobe.com/person/eli-shechtman/" target="blank">Eli Shechtman</a>, 
            <a href="http://www.meyumer.com/" target="blank">Ersin Yumer</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">European Conference on Computer Vision <b>(ECCV)</b>, 2018</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1808.00449" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/video_consistency/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1803.03363/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr18_learn_deblur_prior.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Blind Image Deblurring via Deep Discriminative Priors</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/lerenhanli/homepage" target="blank">Lerenhan Li</a>, 
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Changxin Gao,
            Nong Sang
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2018</div>
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1803.03363" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://link.springer.com/article/10.1007/s11263-018-01146-0" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/lerenhanli/homepage/learn_prior_deblur" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/semi_flow_gan/" target="blank">
            <img class="responsive-img" src="images/publications/nips17_flow.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://filebox.ece.vt.edu/~jbhuang/index.html" target="blank">Jia-Bin Huang</a>
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">Neural Information Processing Systems <b>(NIPS)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://papers.nips.cc/paper/6639-semi-supervised-learning-for-optical-flow-with-generative-adversarial-networks.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/semi_flow_gan/" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/360hyperlapse/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/360hyperlapse.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Semantic-driven Generation of Hyperlapse from 360&deg; Video</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://www.linkedin.com/in/erichuang0771/" target="blank">Yujia Huang</a>, 
            <a href="http://neelj.com/" target="blank">Neel Joshi</a>, 
            <a href="https://www.linkedin.com/in/christopher-buehler-3656a29/" target="blank">Chris Buehler</a>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            and
            <a href="https://www.microsoft.com/en-us/research/people/sbkang/" target="blank">Sing Bing Kang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Visualization and Computer Graphics <b>(TVCG)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1703.10798" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/360hyperlapse/" target="blank">project website</a>
          </div>


        </div>
      </div>



      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1611.06495" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr17_nonblind_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Learning Fully Convolutional Networks for Iterative Non-blind Deconvolution</div>
          <div class="paper-author">
            <a href="https://sites.google.com/site/zhjw1988/" target="blank">Jiawei Zhang</a>,
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>,
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://www.cs.cityu.edu.hk/~rynson/" target="blank">Rynson Lau</a>,
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1611.06495" target="blank">paper</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/deblur_study/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr16_deblur_study.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">A Comparative Study for Single Image Blind Deblurring</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              <a href="https://sites.google.com/site/jbhuang0604/" target="blank">Jia-Bin Huang</a>, 
              <a href="https://eng.ucmerced.edu/people/zhu" target="blank">Zhe Hu</a>, 
              <a href="http://vision.ai.illinois.edu/ahuja.html" target="blank">Narendra Ahuja</a>, and 
              <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2016  (<font color="red">Spotlight presentation</font>)</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://faculty.ucmerced.edu/mhyang/papers/cvpr16_deblurring_benchmark.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/deblur_study/" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/phoenix104104/cvpr16_deblur_study" target="blank">code</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/youtube.jpg">
            <a href="https://www.youtube.com/watch?v=wPWoH-rwJgk" target="blank">CVPR presentation</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/colorline_deblur/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr15_colorline_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Blur Kernel Estimation Using Normalized Color-Line Priors</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              Jian-Jiun Ding, 
              <a href="https://sites.google.com/site/yylinweb/" target="blank">Yen-Yu Lin</a>, and 
              <a href="http://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2015</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://www.csie.ntu.edu.tw/~cyy/publications/papers/Lai2015BKE.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/colorline_deblur/" target="blank">project website</a>
          </div>

        </div>
      </div>
  -->
  </div>

</div>


<!--==========================================
                     Patents
  ===========================================-->
  <div class="section activities-section scrollspy" id="patents">
    <div class="row container">
      <div class="col s12">
        <div class="title">Patents</div>
        <hr>
        <ul class="browser-default" style="padding-left: 0;">
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US12189714B2</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/18/46/cd/a314968b3793d1/US12189714.pdf" target="_blank">
                System and method for improved few-shot object detection using a dynamic semantic network
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US20250182450A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/19/17/25/7bd1d704d1c8e4/US20250182450A1.pdf" target="_blank">
                System and method for weapon detection with pose estimation
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US12266156B2</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/c0/e6/0d/8116b420db2370/US12266156.pdf" target="_blank">
                System and method for solving missing annotation object detection
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US20250005881A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/1c/15/5f/96047766b8a0cb/US20250005881A1.pdf" target="_blank">
                System and method for assigning complex concave polygons as bounding boxes
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US12131497B2</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/6d/28/2d/f5af478099f5da/US12131497.pdf" target="_blank">
                Fast object search based on the cocktail party effect
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US20240355085A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/63/a7/60/429897281cf5ba/US20240355085A1.pdf" target="_blank">
                System and method for matching products and determining spreads and plugs
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US11915463B2</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/6c/4f/d2/c028419482ce23/US20220058425A1.pdf" target="_blank">
                System and method for the automatic enrollment of object images into a gallery
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">WO2020210825A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/d0/1f/08/fe7e8967cd5f3b/US20220083959A1.pdf" target="_blank">
                System and method for detecting products and product labels
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">WO2022211995A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/55/f9/80/52cf50fabd7f8b/US20240104761A1.pdf" target="_blank">
                System and method for using non-axis aligned bounding boxes for retail detection
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">WO2022109295A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/4f/26/06/54a9abee8b12ea/US20230368381A1.pdf" target="_blank">
                System and method for detecting and classifying abnormal cells
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US11954175</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/74/1e/71/db8f766882c578/US11954175.pdf" target="_blank">
                Feature pyramids for object detection
              </a>
            </div>
          </li>
          <li style="display: flex; gap: 16px;">
            <div style="min-width: 160px; font-weight: bold;">US2022058432A1</div>
            <div>
              <a href="https://patentimages.storage.googleapis.com/54/11/b4/f3989385b9ce8a/US12026226.pdf" target="_blank">
                Few-shot object detection using semantic relation reasoning
              </a>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </div>


  <!--==========================================
                     Activities
  ===========================================-->
<div class="section activities-section scrollspy" id="activities">

  <div class="row container">
    <div class="col s12">
      <div class="title">Academic Services</div>
      <hr>
        <ul>
          <b>Conference Reviewer:</b>
          <li>&emsp; &bull; CVPR
              &emsp; &bull; ICCV
              &emsp; &bull; ECCV
            &emsp;   &bull; NeurIPS
              &emsp; &bull; ICLR
            &emsp;   &bull; ICML
          </li>
        </ul>

        <ul>
          <b>Journal Reviewer:</b>
          <li>&emsp; &bull; TIP
                &bull; IJCV
              &emsp; &bull; PR
              &emsp; &bull; TGRS
          </li>
        </ul>

    </div>
    <div class="col s12">
      <div class="title">Teaching</div>
      <hr>
      <ul>
        <b>Graduate Teaching Assistant</b> @ Pattern Recognition Theory, CMU, 2022 Fall
      </ul>
      <ul>
        <b>Graduate Teaching Assistant</b> @ Deep Learning Based Computer Vision and Pattern Recognition, CMU, 2023 Fall, 2024 Fall
      </ul>
    </div>
  </div>
</div>


<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer white lighten-4">
    <!--
    <div class="row">
      <div class="col l4 offset-l4 s12">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=330&t=tt&d=NjaSaq4L045rBnmichOgvAwPcadRYvfRA0vmRVDeG-k"></script>
      </div>
    </div>
    -->
    <div class="footer-copyright center black-text">
      Copyright ¬© Fangyi Chen 2023;
      Sourced from <a href="http://www.wslai.net/" target="blank">Jason Lai</a>
    </div>
  
</footer>


<!--  Scripts-->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="js/materialize.js"></script>
<script src="js/aos.js"></script>
<script src="js/init.js"></script>

</body>
</html>
